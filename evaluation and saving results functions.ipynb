{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c9155-cc2d-4abc-a1bd-7dc4f8d2c897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c66315e-45b8-44d2-9ccf-4f2811494af4",
   "metadata": {},
   "source": [
    "### some custom functions for evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4430b991-b0cd-4900-9186-6a88779f72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_f1_cv_score(model,x_train,n_splits=5,y_train=y_train,random_state=42):\n",
    "  \"\"\"\n",
    "  specify the name of x_train in the 2nd arg.\n",
    "  specify the n_splits for the kfold(def is 5)\n",
    "  y_train is by default with this object name(unless specified otherwise)[not changed a lot:dont have various object names]\n",
    "  - set a fixed random_state for reproducibality\n",
    "  returns accuracy and f1 cv scores\n",
    "  \"\"\"  \n",
    "  strat_kfold=StratifiedKFold(n_splits=n_splits,shuffle=True,random_state=random_state)#n_splits must be odd num\n",
    "  acc_score=cross_val_score(model,x_train,y_train,cv=strat_kfold,scoring=\"accuracy\")\n",
    "  f1_score=cross_val_score(model,x_train,y_train,cv=strat_kfold,scoring=\"f1\")  \n",
    "    \n",
    "    \n",
    "  return acc_score.mean(),f1_score.mean()\n",
    "\n",
    "def acc_f1_score_train(model,x_train,y_train=y_train):\n",
    "    \"\"\"\n",
    "    specify the name of x_train in the 2nd arg.\n",
    "    y_train is by default with this object name(unless specified otherwise)[not changed a lot:dont have various object names]\n",
    "    returns accuracy and f1 scores of predicting x_train\n",
    "    \"\"\"\n",
    "    model.fit(x_train,y_train)\n",
    "    y_train_pred=model.predict(x_train)\n",
    "    \n",
    "    return accuracy_score(y_train,y_train_pred),f1_score(y_train,y_train_pred)\n",
    "\n",
    "def acc_f1_score_test(model,x_train,x_test, y_train=y_train ,y_test=y_test):\n",
    "    \"\"\"\n",
    "    specify the name of x_train and x_test in the 2nd and 3rd argument\n",
    "    -y_train and test is by default with this object name(unless specified otherwise)[not changed a lot:dont have various object names]\n",
    "    returns accuracy and f1 scores of predicting x_test\n",
    "    \"\"\"\n",
    "    model.fit(x_train,y_train)\n",
    "    y_test_pred=model.predict(x_test)\n",
    "    \n",
    "    return accuracy_score(y_test,y_test_pred),f1_score(y_test,y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461a5a72-5006-477b-9f48-44a9be043ed7",
   "metadata": {},
   "source": [
    "### saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a89aec20-3d7b-405b-80e9-6b44be197af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "#poly=[]\n",
    "def_tuned=[]#model with default params or tuned(usie GS/RS/manual Htn on cv)\n",
    "pca=[]#applying pca or not\n",
    "accuracy_lst=[]\n",
    "f1_lst=[]\n",
    "notes=[]\n",
    "#5(or 6 appends if u want to add a norte column) appends for each model(we count def model and tuned model as diff models)\n",
    "def appending(model, default_tuned, pca_no, accuracy, f1, note=None):#add poly list later(a list to specify if poly was applied and w what degree)\n",
    "    '''\n",
    "    *this function appends certain info about the models which we will zipped(or use dict of lists) to be converted to a dataframe and used for visualiztion*\n",
    "    a-initialize the lists outside the function so that they arent reset each time u call the function or b-u can put them inside but make them *global variables* or c-add them as args and return them\n",
    "    args:\n",
    "    1-model:append model name to a list\n",
    "    2-default_tuned:append to a list whether the model is tuned or not\n",
    "    3-pca_no:whether pca was applied or not and num of components\n",
    "    4-accuracy:append accuracy score to a list\n",
    "    5-f1:append f1 score to a list\n",
    "    6-note:to add a note about a certain model ,u can append it to a list\n",
    "    '''\n",
    "    #5(or 6 if u want to add a norte column) appends for each model(we count def model and tuned model as diff models)\n",
    "    models.append(model)\n",
    "    def_tuned.append(default_tuned)\n",
    "    pca.append(pca_no)\n",
    "    accuracy_lst.append(accuracy)\n",
    "    f1_lst.append(f1)\n",
    "    notes.append(note)\n",
    "\n",
    "def generate_dataframe(models=models,def_tuned=def_tuned,pca=pca,accuracy_lst=accuracy_lst,f1_lst=f1_lst,notes=notes):\n",
    "    '''\n",
    "    This function generates a DataFrame from the lists after all appending is done.\n",
    "    Returns:\n",
    "    -DataFrame containing the model comparison data.\n",
    "    '''\n",
    "    # Combine all lists into a *dictionary of lists*\n",
    "    zz = {\n",
    "        'Model': models,\n",
    "        'Tuned/Default': def_tuned,\n",
    "        'PCA': pca,\n",
    "        'Accuracy': accuracy_lst,\n",
    "        'F1 Score': f1_lst,\n",
    "        'Notes': notes\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary into a pandas DataFrame\n",
    "    zzz = pd.DataFrame(zz)\n",
    "    return zzz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d76586-2b51-4b0f-900d-5797c96ed9dd",
   "metadata": {},
   "source": [
    "### example usage with logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9f63218c-be63-4d10-926d-a585b05bc573",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function splitting_train_test in module __main__:\n",
      "\n",
      "splitting_train_test(x, y, encode_x=False, cat_x_encoding='onehot', encoding_map=None, ordinal_orders=None, scaling=False, poly_features=False, poly_degree=2, output_x_numpy=True, y_encoding='label', y_order=None)\n",
      "    *This function is for preprocessing  classification target dataset*\n",
      "    Args:\n",
      "    1-x ( pd.DataFrame): Feature dataframe.(we will return it after split  as numpy.ndarray or as df [so that we can retain column names and indices for train,test datasets])\n",
      "    2-y (pd.Series or np.array): Target variable (binary or multi-claas classification)(should be 1d array to be suitable for ML models.(use label or ordinal encoding or mapping)\n",
      "    3-encode_x (bool)*[default is False]*: Whether to encode categorical features in x.(for most ML models u should encode features into numbers except:cat_boost for eg.)\n",
      "    4-cat_x_encoding (str)[default is 'onehot']: Encoding type for categorical features. Choose from 'onehot', 'label', or 'ordinal'or'mixed'.\n",
      "    5-encoding_map(dictionary)[default is None]:specify different encodings to differnt categorical features(dict.)\n",
      "    6-ordinal_orders(dictionary)[default is None]:specify the order of each categorical column that will have ordinal encoding applied on it\n",
      "    7-scaling (bool)*[default is False]*: Whether to scale numerical features in x.\n",
      "    8-poly_features(boolean):the default is False\n",
      "    7-poly_degree(int)(default is 2):sets the n_degree of the ploy function if applied\n",
      "    8-output_x_numpy (bool)*[def is True]*: Whether to return x_train, x_test as NumPy arrays(less computation and compatible with ML models but the drawback is the inability to retain col names,indices)\n",
      "    9-y_encoding(str)(default is 'label'):choose to whether encode the target by label or ordinal encoding.\n",
      "    10-y_order(default is none)(dictionary):only if u choose y_encoding to be ordinal\n",
      "    **Returns:**\n",
      "        tuple:1,2- Processed (x_train, x_test) as numpy arrays or dfs ,u choose to return them with encoding/scaling or both or none.\n",
      "              3,4-, y_train, y_test as 1d numpy.arrays(to be suitable for most ML models)\n",
      "    ***global variables from the function:y_label_mapping,y_ordinal_mapping\n",
      "    ----------\n",
      "    *if binary class.:we will encode the whole y to zeroes and ones(binary classification) by label encoding or .map or .replace not one hot-encoding(as it creates col for each cat)\n",
      "    as this is needed for most ML class. models(need y as 1d array or pd.series)\n",
      "    and this wont lead to data leakage as it is independant on the features.*\n",
      "    ***we can encode y or just manualluy use .map or .replace...***\n",
      "    -no data leakage as:\n",
      "    **the models train on the features(x) not the target(y)**\n",
      "    *in this function we will return the x(train,test) as numpy.ndarray or dfs and y(train,test) as numpy array(use df.values)*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(splitting_train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f66a9d78-3081-4fe4-9399-bda583181a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv mean of accuaracy and f1 scores:(0.6313754869643392, 0.6473071511451157)\n"
     ]
    }
   ],
   "source": [
    "x,y=split_features_target(df, 'ejection fraction', print_check=False, object_as_cat=True)\n",
    "x_train,x_test,y_train,y_test=splitting_train_test(x, y, encode_x=True, scaling =True ,output_x_numpy=True)#encode and scale features(x)\n",
    "lo=LogisticRegression()\n",
    "print(f'cv mean of accuaracy and f1 scores:{acc_f1_cv_score(lo,x_train)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "019e5342-75e6-4119-ac69-ff482299647a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score (test): 0.550561797752809\n",
      "f1 score (test): 0.5789473684210527\n"
     ]
    }
   ],
   "source": [
    "x_train,x_test,y_train,y_test=splitting_train_test(x, y, encode_x=True,scaling =True,output_x_numpy=True)#encode and scale features(x)\n",
    "lo=LogisticRegression()\n",
    "acc_lo,f1_lo=acc_f1_score_test(lo, x_train, x_test)\n",
    "print(\"accuracy score (test):\",acc_lo)\n",
    "print(\"f1 score (test):\",f1_lo)\n",
    "appending('LogisticRegression','default','no',acc_lo,f1_lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "07da12b0-78ab-4336-a590-c3d2fdbd2754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA applied with 9 components.\n",
      "accuracy score (test): 0.5561797752808989\n",
      "f1 score (test): 0.582010582010582\n"
     ]
    }
   ],
   "source": [
    "#with pca\n",
    "x_train,x_test,y_train,y_test=splitting_train_test(x, y, encode_x=True, scaling =True ,output_x_numpy=True)#encode and scale features(x)\n",
    "x_train_pca_9d, x_test_pca_9d, pca_9d, cum_sum_9d=plot_pca_variance_elbow(x_train, x_test, n_components=9, plot=False, interactive=False, figsize=(8, 5))\n",
    "lo=LogisticRegression()\n",
    "acc_lo2,f1_lo2=acc_f1_score_test(lo, x_train_pca_9d, x_test_pca_9d)\n",
    "print(\"accuracy score (test):\",acc_lo2)\n",
    "print(\"f1 score (test):\",f1_lo2)\n",
    "appending(\"LogisticRegression\",'default','yes,9',acc_lo2,f1_lo2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f9786b-87d0-4864-afd3-8f87cfc9060b",
   "metadata": {},
   "source": [
    "### with this workflow u can automize preprocessing to your preference as well easily save ur results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae414260-31ad-4f72-b095-a6a4abfb0ad8",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18725da5-9fc4-49d1-aa39-9146d49c7e76",
   "metadata": {},
   "source": [
    "### now u can display ur results to comapre between different models with different parameters and evaluation metrics and save it as an excel sheet or keep as DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ef65eeaf-f0d3-4660-8751-0d3931f819b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary=generate_dataframe()\n",
    "# display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "7346682f-4de5-49b2-b607-43dcfaed6db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no' 'yes,9' 'pca cant work with catboost']\n",
      "[None 'used label encoding'\n",
      " 'tuning hyperparameters except n_neighbors didnt have an impact']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Tuned/Default</th>\n",
       "      <th>PCA</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Notes</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>default</td>\n",
       "      <td>no pca</td>\n",
       "      <td>0.550562</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>default</td>\n",
       "      <td>pca 9</td>\n",
       "      <td>0.556180</td>\n",
       "      <td>0.582011</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tuned</td>\n",
       "      <td>no pca</td>\n",
       "      <td>0.556180</td>\n",
       "      <td>0.655022</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>tuned</td>\n",
       "      <td>pca 9</td>\n",
       "      <td>0.556180</td>\n",
       "      <td>0.594872</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>default</td>\n",
       "      <td>no pca</td>\n",
       "      <td>0.528090</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree Classifier</td>\n",
       "      <td>default</td>\n",
       "      <td>pca 9</td>\n",
       "      <td>0.511236</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Support Vector Classifier(SVC)</td>\n",
       "      <td>default</td>\n",
       "      <td>no pca</td>\n",
       "      <td>0.561798</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Support Vector Classifier(SVC)</td>\n",
       "      <td>default</td>\n",
       "      <td>pca 9</td>\n",
       "      <td>0.544944</td>\n",
       "      <td>0.580311</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Support Vector Classifier(SVC)</td>\n",
       "      <td>tuned</td>\n",
       "      <td>no pca</td>\n",
       "      <td>0.561798</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Support Vector Classifier(SVC)</td>\n",
       "      <td>tuned</td>\n",
       "      <td>pca 9</td>\n",
       "      <td>0.561798</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>default</td>\n",
       "      <td>no pca</td>\n",
       "      <td>0.511236</td>\n",
       "      <td>0.558376</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>default</td>\n",
       "      <td>pca 9</td>\n",
       "      <td>0.511236</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>tuned</td>\n",
       "      <td>no pca</td>\n",
       "      <td>0.556180</td>\n",
       "      <td>0.586387</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>tuned</td>\n",
       "      <td>pca 9</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>xgb</td>\n",
       "      <td>default</td>\n",
       "      <td>no pca</td>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.581633</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>xgb</td>\n",
       "      <td>default</td>\n",
       "      <td>pca 9</td>\n",
       "      <td>0.522472</td>\n",
       "      <td>0.572864</td>\n",
       "      <td>used label encoding</td>\n",
       "      <td>label encoding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>xgb</td>\n",
       "      <td>tuned</td>\n",
       "      <td>no pca</td>\n",
       "      <td>0.556180</td>\n",
       "      <td>0.590674</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>xgb</td>\n",
       "      <td>tuned</td>\n",
       "      <td>pca 9</td>\n",
       "      <td>0.556180</td>\n",
       "      <td>0.603015</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>knn9</td>\n",
       "      <td>default(only tuned n_neighbors)</td>\n",
       "      <td>no pca</td>\n",
       "      <td>0.578652</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>tuning hyperparameters except n_neighbors didn...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>knn9</td>\n",
       "      <td>default(only tuned n_neighbors)</td>\n",
       "      <td>pca 9</td>\n",
       "      <td>0.578652</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>tuning hyperparameters except n_neighbors didn...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>catboost</td>\n",
       "      <td>default</td>\n",
       "      <td>pca cant work with catboost</td>\n",
       "      <td>0.511236</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>None</td>\n",
       "      <td>one-hot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Model                    Tuned/Default  \\\n",
       "0               LogisticRegression                          default   \n",
       "1               LogisticRegression                          default   \n",
       "2               LogisticRegression                            tuned   \n",
       "3               LogisticRegression                            tuned   \n",
       "4         Decision Tree Classifier                          default   \n",
       "5         Decision Tree Classifier                          default   \n",
       "6   Support Vector Classifier(SVC)                          default   \n",
       "7   Support Vector Classifier(SVC)                          default   \n",
       "8   Support Vector Classifier(SVC)                            tuned   \n",
       "9   Support Vector Classifier(SVC)                            tuned   \n",
       "10          RandomForestClassifier                          default   \n",
       "11          RandomForestClassifier                          default   \n",
       "12          RandomForestClassifier                            tuned   \n",
       "13          RandomForestClassifier                            tuned   \n",
       "14                             xgb                          default   \n",
       "15                             xgb                          default   \n",
       "16                             xgb                            tuned   \n",
       "17                             xgb                            tuned   \n",
       "18                            knn9  default(only tuned n_neighbors)   \n",
       "19                            knn9  default(only tuned n_neighbors)   \n",
       "20                        catboost                          default   \n",
       "\n",
       "                            PCA  Accuracy  F1 Score  \\\n",
       "0                        no pca  0.550562  0.578947   \n",
       "1                         pca 9  0.556180  0.582011   \n",
       "2                        no pca  0.556180  0.655022   \n",
       "3                         pca 9  0.556180  0.594872   \n",
       "4                        no pca  0.528090  0.553191   \n",
       "5                         pca 9  0.511236  0.524590   \n",
       "6                        no pca  0.561798  0.593750   \n",
       "7                         pca 9  0.544944  0.580311   \n",
       "8                        no pca  0.561798  0.632075   \n",
       "9                         pca 9  0.561798  0.632075   \n",
       "10                       no pca  0.511236  0.558376   \n",
       "11                        pca 9  0.511236  0.524590   \n",
       "12                       no pca  0.556180  0.586387   \n",
       "13                        pca 9  0.539326  0.572917   \n",
       "14                       no pca  0.539326  0.581633   \n",
       "15                        pca 9  0.522472  0.572864   \n",
       "16                       no pca  0.556180  0.590674   \n",
       "17                        pca 9  0.556180  0.603015   \n",
       "18                       no pca  0.578652  0.637681   \n",
       "19                        pca 9  0.578652  0.637681   \n",
       "20  pca cant work with catboost  0.511236  0.553846   \n",
       "\n",
       "                                                Notes        encoding  \n",
       "0                                                None         one-hot  \n",
       "1                                                None         one-hot  \n",
       "2                                                None         one-hot  \n",
       "3                                                None         one-hot  \n",
       "4                                                None         one-hot  \n",
       "5                                                None         one-hot  \n",
       "6                                                None         one-hot  \n",
       "7                                                None         one-hot  \n",
       "8                                                None         one-hot  \n",
       "9                                                None         one-hot  \n",
       "10                                               None         one-hot  \n",
       "11                                               None         one-hot  \n",
       "12                                               None         one-hot  \n",
       "13                                               None         one-hot  \n",
       "14                                               None         one-hot  \n",
       "15                                used label encoding  label encoding  \n",
       "16                                               None         one-hot  \n",
       "17                                               None         one-hot  \n",
       "18  tuning hyperparameters except n_neighbors didn...            None  \n",
       "19  tuning hyperparameters except n_neighbors didn...            None  \n",
       "20                                               None         one-hot  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(summary['PCA'].unique())\n",
    "summary['PCA'] = summary['PCA'].replace( ['no', 'yes,9'],['no pca', 'pca 9'])\n",
    "print(summary['Notes'].unique())\n",
    "summary['encoding']=summary['Notes']\n",
    "#.apply can only take one main if and else so ternary method will be used\n",
    "#value_if_condition_true if condition else value_if_condition_false\n",
    "summary['encoding'] = summary['encoding'].apply(\n",
    "    lambda x: 'one-hot' if x is None \n",
    "    else ('label encoding' if x == 'used label encoding' \n",
    "          else ('no encoding and no split to train,test' if x == 'unsplit data' \n",
    "                else (None if x=='tuning hyperparameters except n_neighbors didnt have an impact' else x)))\n",
    ")\n",
    "\n",
    "display(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "79cf3885-c931-45c6-a3f7-7e9bf8e0816f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the results as .csv file or excel sheet\n",
    "import os\n",
    "save_dir=os.path.join(r\"C:\\Users\\MY PC\\Documents\\python_notebooks\\projects\\project 1\",\"saved results.csv\")\n",
    "summary.to_csv(save_dir,index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
